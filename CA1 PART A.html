<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>8b07d4ec17c54017993e0db5bae27070</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="data-preparation" class="cell markdown" id="44675cf3">
<h2>DATA PREPARATION</h2>
</section>
<div class="cell code" data-execution_count="1" id="97e77bdc">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> mean</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> std</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> fashion_mnist</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Conv2D</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> MaxPooling2D</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> BatchNormalization</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dropout</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Flatten</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> SGD</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="2" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="a64419c9" data-outputId="d7d0cb62-92d8-4433-8426-49f3df384e8b">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> tf.keras.datasets.fashion_mnist.load_data()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X_train.shape <span class="op">==</span> (<span class="dv">60000</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X_test.shape <span class="op">==</span> (<span class="dv">10000</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> y_train.shape <span class="op">==</span> (<span class="dv">60000</span>,)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> y_test.shape <span class="op">==</span> (<span class="dv">10000</span>,)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
29515/29515 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26421880/26421880 [==============================] - 3s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
5148/5148 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4422102/4422102 [==============================] - 0s 0us/step
</code></pre>
</div>
</div>
<section id="data-visualization" class="cell markdown" id="bPgwL4Z5KMEd">
<h2>DATA VISUALIZATION</h2>
</section>
<div class="cell markdown" id="6674e443">
<p>Creating a dictionary to store all the diferent type of images</p>
</div>
<div class="cell code" id="ZL8688hmJWJ7">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>fashion_items <span class="op">=</span> {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a> <span class="dv">0</span>: <span class="st">&#39;T-shirt/top&#39;</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a> <span class="dv">1</span>: <span class="st">&#39;Trouser&#39;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a> <span class="dv">2</span>: <span class="st">&#39;Pullover&#39;</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a> <span class="dv">3</span>: <span class="st">&#39;Dress&#39;</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a> <span class="dv">4</span>: <span class="st">&#39;Coat&#39;</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a> <span class="dv">5</span>: <span class="st">&#39;Sandal&#39;</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a> <span class="dv">6</span>: <span class="st">&#39;Shirt&#39;</span>,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a> <span class="dv">7</span>: <span class="st">&#39;Sneaker&#39;</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a> <span class="dv">8</span>: <span class="st">&#39;Bag&#39;</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a> <span class="dv">9</span>: <span class="st">&#39;Ankle boot&#39;</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:482,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="bC74doyfJQKP" data-outputId="4b5b5cce-c21c-4752-9898-0280e4951814">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="dv">20</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">5</span>,<span class="dv">5</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    plt.imshow(X_train[i] )</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    plt.title( fashion_items[(y_train[i]) ])</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    plt.xticks([])</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    plt.yticks([])</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/e603ca1183778a94830c004f36f9d96c082aa192.png" /></p>
</div>
</div>
<section id="data-preprocessing" class="cell markdown" id="-xhuK-RzKWyJ">
<h2>DATA PREPROCESSING</h2>
</section>
<div class="cell code" data-execution_count="3" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ySxwyZbtyVAe" data-outputId="aff6b20a-6f63-4adb-ff78-0021a9f97282">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">1</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;X_train shape: &quot;</span>,X_train.shape)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;X_test shape: &quot;</span>,X_test.shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>X_train shape:  (60000, 28, 28, 1)
X_test shape:  (10000, 28, 28, 1)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="4" id="ejfTuR-WyZDe">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode target values</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode target values</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> to_categorical(y_train,<span class="dv">10</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> to_categorical(y_test,<span class="dv">10</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="5" id="J1FY1S8zyoej">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># scale pixels</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_pixels(train, test):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert from integers to floats</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    train_norm <span class="op">=</span> train.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    test_norm <span class="op">=</span> test.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize to range 0-1</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    train_norm <span class="op">=</span> train_norm <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    test_norm <span class="op">=</span> test_norm <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return normalized images</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_norm, test_norm</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="6" id="bdNsG82vy8A4">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> prep_pixels(X_train, X_test)</span></code></pre></div>
</div>
<section id="training-and-evaluation" class="cell markdown" id="b0037233">
<h2>TRAINING AND EVALUATION</h2>
</section>
<section id="building-baseline-model" class="cell markdown" id="bb8127ae">
<h2>Building baseline model</h2>
</section>
<div class="cell code" id="e0335228">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Vxh4ralgBR16" data-outputId="7cdf5b0f-f493-419b-b959-a8d530827f7e">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">100</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/20
600/600 [==============================] - 3s 4ms/step - loss: 0.4282 - accuracy: 0.8501 - val_loss: 0.3292 - val_accuracy: 0.8786
Epoch 2/20
600/600 [==============================] - 2s 4ms/step - loss: 0.2786 - accuracy: 0.9003 - val_loss: 0.3069 - val_accuracy: 0.8841
Epoch 3/20
600/600 [==============================] - 2s 4ms/step - loss: 0.2340 - accuracy: 0.9146 - val_loss: 0.2596 - val_accuracy: 0.9029
Epoch 4/20
600/600 [==============================] - 2s 4ms/step - loss: 0.2052 - accuracy: 0.9244 - val_loss: 0.2711 - val_accuracy: 0.9019
Epoch 5/20
600/600 [==============================] - 2s 4ms/step - loss: 0.1817 - accuracy: 0.9328 - val_loss: 0.2622 - val_accuracy: 0.9039
Epoch 6/20
600/600 [==============================] - 2s 4ms/step - loss: 0.1611 - accuracy: 0.9406 - val_loss: 0.2662 - val_accuracy: 0.9073
Epoch 7/20
600/600 [==============================] - 2s 4ms/step - loss: 0.1447 - accuracy: 0.9464 - val_loss: 0.2559 - val_accuracy: 0.9146
Epoch 8/20
600/600 [==============================] - 2s 4ms/step - loss: 0.1273 - accuracy: 0.9531 - val_loss: 0.2607 - val_accuracy: 0.9159
Epoch 9/20
600/600 [==============================] - 2s 4ms/step - loss: 0.1161 - accuracy: 0.9572 - val_loss: 0.2724 - val_accuracy: 0.9119
Epoch 10/20
600/600 [==============================] - 2s 4ms/step - loss: 0.1014 - accuracy: 0.9628 - val_loss: 0.2726 - val_accuracy: 0.9127
Epoch 11/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.9667 - val_loss: 0.2790 - val_accuracy: 0.9144
Epoch 12/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0824 - accuracy: 0.9695 - val_loss: 0.3088 - val_accuracy: 0.9081
Epoch 13/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0690 - accuracy: 0.9754 - val_loss: 0.3129 - val_accuracy: 0.9151
Epoch 14/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0663 - accuracy: 0.9759 - val_loss: 0.3352 - val_accuracy: 0.9077
Epoch 15/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.3235 - val_accuracy: 0.9191
Epoch 16/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0465 - accuracy: 0.9836 - val_loss: 0.3456 - val_accuracy: 0.9152
Epoch 17/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9845 - val_loss: 0.3687 - val_accuracy: 0.9093
Epoch 18/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.3657 - val_accuracy: 0.9123
Epoch 19/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0333 - accuracy: 0.9888 - val_loss: 0.3647 - val_accuracy: 0.9191
Epoch 20/20
600/600 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.3914 - val_accuracy: 0.9170
&gt; 91.700
Baseline Error: 8.30%
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="VAzHBT0sCJTP" data-outputId="2f5122fa-0363-4573-a3a8-262cb7c81e79">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/7975e0ad20efd16cc0461fbecaccc21b202f99a6.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="M2dQ4DisCPhL" data-outputId="1c2d9324-7598-4d2a-978a-df9766bc0368">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model: 99.05499815940857
Train loss of the model:  0.030595794320106506
Validation accuracy of the model:  0.9169999957084656
Validation loss of the model:  0.3913671374320984
Test Loss: 0.39136719703674316
Test Accuracy: 0.9169999957084656
</code></pre>
</div>
</div>
<div class="cell markdown" id="8c94b3d9">
<p>The validation loss is very high and and the validation accuracy could be better thus we will be improvising the model</p>
</div>
<section id="improving-the-model" class="cell markdown" id="QlbGcGwtEzhM">
<h1>Improving the model</h1>
</section>
<section id="1-adding-more-padding-convolutions-and-filters" class="cell markdown" id="Ru2NRikz-oy1">
<h2>1. Adding more padding convolutions and filters</h2>
</section>
<div class="cell code" id="alYC-dfm-FSj">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>,kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">28</span>,<span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="rTCG78rv-vXh" data-outputId="efb5a298-17e2-4a1b-947a-f18ca2710d67">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">100</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/10
600/600 [==============================] - 12s 7ms/step - loss: 0.4266 - accuracy: 0.8444 - val_loss: 0.3159 - val_accuracy: 0.8846
Epoch 2/10
600/600 [==============================] - 4s 6ms/step - loss: 0.2680 - accuracy: 0.9011 - val_loss: 0.2629 - val_accuracy: 0.9039
Epoch 3/10
600/600 [==============================] - 4s 6ms/step - loss: 0.2197 - accuracy: 0.9191 - val_loss: 0.2438 - val_accuracy: 0.9119
Epoch 4/10
600/600 [==============================] - 4s 6ms/step - loss: 0.1871 - accuracy: 0.9314 - val_loss: 0.2349 - val_accuracy: 0.9148
Epoch 5/10
600/600 [==============================] - 4s 6ms/step - loss: 0.1611 - accuracy: 0.9399 - val_loss: 0.2243 - val_accuracy: 0.9173
Epoch 6/10
600/600 [==============================] - 4s 6ms/step - loss: 0.1400 - accuracy: 0.9479 - val_loss: 0.2241 - val_accuracy: 0.9219
Epoch 7/10
600/600 [==============================] - 4s 6ms/step - loss: 0.1198 - accuracy: 0.9547 - val_loss: 0.2366 - val_accuracy: 0.9211
Epoch 8/10
600/600 [==============================] - 4s 6ms/step - loss: 0.0995 - accuracy: 0.9634 - val_loss: 0.2588 - val_accuracy: 0.9203
Epoch 9/10
600/600 [==============================] - 4s 6ms/step - loss: 0.0856 - accuracy: 0.9682 - val_loss: 0.3035 - val_accuracy: 0.9140
Epoch 10/10
600/600 [==============================] - 4s 6ms/step - loss: 0.0735 - accuracy: 0.9726 - val_loss: 0.3288 - val_accuracy: 0.9150
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="MidfGw8p-vaA" data-outputId="85c4c300-39e8-4f01-999c-9219c85d7599">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/8ed3082d47be504ae174a9be30feac7b5ec2b3e0.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="pQRGdnylBCd-" data-outputId="8e8356e7-2379-4de6-f165-711403b3910d">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model: 97.25666642189026
Train loss of the model:  0.07350565493106842
Validation accuracy of the model:  0.9150000214576721
Validation loss of the model:  0.32883408665657043
Test Loss: 0.32883399724960327
Test Accuracy: 0.9150000214576721
</code></pre>
</div>
</div>
<div class="cell markdown" id="b8c019a8">
<p>This did not really change the values much so we will now proceed to regularization techniques</p>
</div>
<section id="2-increased-padding-and-filters--dropout--batch-normalization" class="cell markdown" id="VMLxljuqF5k2">
<h2>2. Increased padding and filters + Dropout + Batch Normalization</h2>
</section>
<div class="cell code" id="hNIGXSTkF-Pa">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>,kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">28</span>,<span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.3</span>))</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.4</span>))</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Ysa7wjvlE1Ed" data-outputId="42a0d483-4de4-4595-a78e-620c3b4267c2">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">100</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/10
600/600 [==============================] - 5s 7ms/step - loss: 0.5480 - accuracy: 0.8027 - val_loss: 0.3572 - val_accuracy: 0.8661
Epoch 2/10
600/600 [==============================] - 4s 7ms/step - loss: 0.3700 - accuracy: 0.8634 - val_loss: 0.3366 - val_accuracy: 0.8780
Epoch 3/10
600/600 [==============================] - 4s 7ms/step - loss: 0.3231 - accuracy: 0.8806 - val_loss: 0.3096 - val_accuracy: 0.8824
Epoch 4/10
600/600 [==============================] - 5s 8ms/step - loss: 0.2942 - accuracy: 0.8908 - val_loss: 0.2871 - val_accuracy: 0.8926
Epoch 5/10
600/600 [==============================] - 4s 7ms/step - loss: 0.2752 - accuracy: 0.8972 - val_loss: 0.2439 - val_accuracy: 0.9118
Epoch 6/10
600/600 [==============================] - 6s 10ms/step - loss: 0.2583 - accuracy: 0.9041 - val_loss: 0.2455 - val_accuracy: 0.9070
Epoch 7/10
600/600 [==============================] - 5s 9ms/step - loss: 0.2511 - accuracy: 0.9063 - val_loss: 0.2543 - val_accuracy: 0.9049
Epoch 8/10
600/600 [==============================] - 5s 8ms/step - loss: 0.2418 - accuracy: 0.9100 - val_loss: 0.2325 - val_accuracy: 0.9154
Epoch 9/10
600/600 [==============================] - 4s 7ms/step - loss: 0.2324 - accuracy: 0.9135 - val_loss: 0.2268 - val_accuracy: 0.9180
Epoch 10/10
600/600 [==============================] - 4s 7ms/step - loss: 0.2308 - accuracy: 0.9149 - val_loss: 0.2323 - val_accuracy: 0.9167
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="GpYfpRjGE1Ge" data-outputId="57341996-3da8-48bb-aedf-57bcfb92b3b8">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/c3ba3b25a5df3ad0be509d7a1533abe962afa771.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="3aSIP44pFVge" data-outputId="b38cfdd4-fa97-42ab-e92c-5e4fae027d25">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model: 91.4900004863739
Train loss of the model:  0.23082219064235687
Validation accuracy of the model:  0.916700005531311
Validation loss of the model:  0.2323167473077774
Test Loss: 0.232316792011261
Test Accuracy: 0.916700005531311
</code></pre>
</div>
</div>
<div class="cell markdown" id="141169c3">
<p>The scores look good and based on the graphs, it seems to perform better with increasing number of epoch and thus we wil be increasing the number of epoch to 30</p>
</div>
<div class="cell code" id="cd39638d">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting with 30 epoch</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="3dqpwFEjRxpi" data-outputId="47c0607e-a21c-483b-ba77-fa821c57fd9e">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">30</span>, batch_size<span class="op">=</span><span class="dv">100</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/30
600/600 [==============================] - 5s 8ms/step - loss: 0.2260 - accuracy: 0.9153 - val_loss: 0.2514 - val_accuracy: 0.9062
Epoch 2/30
600/600 [==============================] - 4s 7ms/step - loss: 0.2144 - accuracy: 0.9209 - val_loss: 0.2340 - val_accuracy: 0.9144
Epoch 3/30
600/600 [==============================] - 5s 8ms/step - loss: 0.2130 - accuracy: 0.9217 - val_loss: 0.2346 - val_accuracy: 0.9167
Epoch 4/30
600/600 [==============================] - 4s 7ms/step - loss: 0.2044 - accuracy: 0.9234 - val_loss: 0.2212 - val_accuracy: 0.9202
Epoch 5/30
600/600 [==============================] - 4s 7ms/step - loss: 0.2055 - accuracy: 0.9234 - val_loss: 0.2285 - val_accuracy: 0.9189
Epoch 6/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1980 - accuracy: 0.9275 - val_loss: 0.2164 - val_accuracy: 0.9211
Epoch 7/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1975 - accuracy: 0.9273 - val_loss: 0.1999 - val_accuracy: 0.9293
Epoch 8/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1895 - accuracy: 0.9296 - val_loss: 0.2108 - val_accuracy: 0.9249
Epoch 9/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1859 - accuracy: 0.9316 - val_loss: 0.2111 - val_accuracy: 0.9237
Epoch 10/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1813 - accuracy: 0.9329 - val_loss: 0.1976 - val_accuracy: 0.9291
Epoch 11/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1762 - accuracy: 0.9340 - val_loss: 0.2085 - val_accuracy: 0.9255
Epoch 12/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1770 - accuracy: 0.9344 - val_loss: 0.2210 - val_accuracy: 0.9195
Epoch 13/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1716 - accuracy: 0.9362 - val_loss: 0.2171 - val_accuracy: 0.9212
Epoch 14/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1705 - accuracy: 0.9355 - val_loss: 0.2067 - val_accuracy: 0.9270
Epoch 15/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1668 - accuracy: 0.9380 - val_loss: 0.1952 - val_accuracy: 0.9318
Epoch 16/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1638 - accuracy: 0.9387 - val_loss: 0.2048 - val_accuracy: 0.9299
Epoch 17/30
600/600 [==============================] - 6s 10ms/step - loss: 0.1617 - accuracy: 0.9393 - val_loss: 0.2056 - val_accuracy: 0.9275
Epoch 18/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1583 - accuracy: 0.9401 - val_loss: 0.2045 - val_accuracy: 0.9275
Epoch 19/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1565 - accuracy: 0.9402 - val_loss: 0.2035 - val_accuracy: 0.9293
Epoch 20/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1555 - accuracy: 0.9416 - val_loss: 0.2107 - val_accuracy: 0.9267
Epoch 21/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1523 - accuracy: 0.9436 - val_loss: 0.2136 - val_accuracy: 0.9287
Epoch 22/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1481 - accuracy: 0.9441 - val_loss: 0.2063 - val_accuracy: 0.9289
Epoch 23/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1489 - accuracy: 0.9447 - val_loss: 0.2068 - val_accuracy: 0.9292
Epoch 24/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1431 - accuracy: 0.9465 - val_loss: 0.2051 - val_accuracy: 0.9305
Epoch 25/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1451 - accuracy: 0.9456 - val_loss: 0.1921 - val_accuracy: 0.9362
Epoch 26/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1424 - accuracy: 0.9463 - val_loss: 0.2084 - val_accuracy: 0.9272
Epoch 27/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1402 - accuracy: 0.9473 - val_loss: 0.2113 - val_accuracy: 0.9257
Epoch 28/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1390 - accuracy: 0.9477 - val_loss: 0.2045 - val_accuracy: 0.9332
Epoch 29/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1367 - accuracy: 0.9485 - val_loss: 0.1949 - val_accuracy: 0.9355
Epoch 30/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1354 - accuracy: 0.9489 - val_loss: 0.1968 - val_accuracy: 0.9333
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ck4OIVrzRqUI" data-outputId="366703a0-8b0d-40aa-e907-74ecfb74fbe8">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/1308697fd88a38c727222300beb6fe309c73ed8a.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="UC_GyAnxBRP_" data-outputId="314d1108-bf1d-4fe0-91e4-24c93a664055">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model: 94.88833546638489
Train loss of the model:  0.1354120969772339
Validation accuracy of the model:  0.9333000183105469
Validation loss of the model:  0.19677622616291046
Test Loss: 0.19677621126174927
Test Accuracy: 0.9333000183105469
</code></pre>
</div>
</div>
<div class="cell markdown" id="e626095b">
<p>The test accuracy is actually higher now so it shows that dropout + batch normalization actually does improve performance</p>
</div>
<section id="3-increased-padding-and-filters--dropout--batch-normalization--data-augmentation" class="cell markdown" id="UOC4pby2H8AS">
<h2>3. Increased padding and filters + Dropout + Batch Normalization + Data Augmentation</h2>
</section>
<div class="cell code" data-execution_count="7" id="iTkJhSq-IPaL">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>,kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">28</span>,<span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.3</span>))</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.4</span>))</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="8" id="KnaJzBKMH-gl">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>datagen <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>        featurewise_center<span class="op">=</span><span class="va">False</span>,  <span class="co"># set input mean to 0 over the dataset</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>        samplewise_center<span class="op">=</span><span class="va">False</span>,  <span class="co"># set each sample mean to 0</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>        featurewise_std_normalization<span class="op">=</span><span class="va">False</span>,  <span class="co"># divide inputs by std of the dataset</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>        samplewise_std_normalization<span class="op">=</span><span class="va">False</span>,  <span class="co"># divide each input by its std</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>        zca_whitening<span class="op">=</span><span class="va">False</span>,  <span class="co"># dimesion reduction</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        rotation_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly rotate images in the range</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        zoom_range <span class="op">=</span> <span class="fl">0.1</span>, <span class="co"># Randomly zoom image</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>        width_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images horizontally</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        height_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images vertically</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>        horizontal_flip<span class="op">=</span><span class="va">False</span>,  <span class="co"># randomly flip images</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>        vertical_flip<span class="op">=</span><span class="va">False</span>)  <span class="co"># randomly flip images</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>datagen.fit(X_train)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="9" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="iR260RV4H-i3" data-outputId="8d9ee483-dc80-49e8-b620-f7f69d6c89e3">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(datagen.flow(X_train, y_train, batch_size<span class="op">=</span><span class="dv">100</span>),shuffle<span class="op">=</span><span class="va">True</span>, epochs<span class="op">=</span><span class="dv">10</span>, validation_data <span class="op">=</span> (X_test, y_test),</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>                              verbose <span class="op">=</span> <span class="dv">2</span>, steps_per_epoch<span class="op">=</span>X_train.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">100</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/10
600/600 - 31s - loss: 0.7181 - accuracy: 0.7329 - val_loss: 0.4821 - val_accuracy: 0.8196 - 31s/epoch - 52ms/step
Epoch 2/10
600/600 - 22s - loss: 0.4949 - accuracy: 0.8112 - val_loss: 0.3729 - val_accuracy: 0.8637 - 22s/epoch - 37ms/step
Epoch 3/10
600/600 - 21s - loss: 0.4380 - accuracy: 0.8341 - val_loss: 0.3650 - val_accuracy: 0.8614 - 21s/epoch - 35ms/step
Epoch 4/10
600/600 - 21s - loss: 0.4161 - accuracy: 0.8415 - val_loss: 0.3516 - val_accuracy: 0.8673 - 21s/epoch - 36ms/step
Epoch 5/10
600/600 - 22s - loss: 0.3861 - accuracy: 0.8536 - val_loss: 0.3785 - val_accuracy: 0.8567 - 22s/epoch - 36ms/step
Epoch 6/10
600/600 - 21s - loss: 0.3759 - accuracy: 0.8579 - val_loss: 0.3159 - val_accuracy: 0.8832 - 21s/epoch - 35ms/step
Epoch 7/10
600/600 - 22s - loss: 0.3610 - accuracy: 0.8647 - val_loss: 0.3080 - val_accuracy: 0.8899 - 22s/epoch - 37ms/step
Epoch 8/10
600/600 - 22s - loss: 0.3474 - accuracy: 0.8698 - val_loss: 0.2739 - val_accuracy: 0.8997 - 22s/epoch - 36ms/step
Epoch 9/10
600/600 - 22s - loss: 0.3377 - accuracy: 0.8735 - val_loss: 0.2741 - val_accuracy: 0.8967 - 22s/epoch - 36ms/step
Epoch 10/10
600/600 - 21s - loss: 0.3306 - accuracy: 0.8770 - val_loss: 0.2731 - val_accuracy: 0.8979 - 21s/epoch - 35ms/step
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="10" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="gHV8udjPIRff" data-outputId="5b7d0416-951c-4702-ceee-58adc8999bd8">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/7e5f8a4bbb9b743084b9b87d9e1f3629093fe5d3.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="11" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="05fdf983" data-outputId="5d5ac931-e4b1-4ac9-f9a1-b72bb8258be4">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model: 87.70333528518677
Train loss of the model:  0.3305641710758209
Validation accuracy of the model:  0.8978999853134155
Validation loss of the model:  0.2730759382247925
Test Loss: 0.2730759382247925
Test Accuracy: 0.8978999853134155
</code></pre>
</div>
</div>
<div class="cell markdown" id="7e14a7e9">
<p>The scores look good and based on the graphs, it seems to perform better with increasing number of epoch and thus we wil be increasing the number of epoch to 30</p>
</div>
<div class="cell code" id="2300b7ec">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting in with 30 epoch</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="un_U_U2DDLzK" data-outputId="35093d45-7381-4c8b-806b-9a54e0d97dc3">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(datagen.flow(X_train, y_train, batch_size<span class="op">=</span><span class="dv">100</span>),shuffle<span class="op">=</span><span class="va">True</span>, epochs<span class="op">=</span><span class="dv">30</span>, validation_data <span class="op">=</span> (X_test, y_test),</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>                              verbose <span class="op">=</span> <span class="dv">2</span>, steps_per_epoch<span class="op">=</span>X_train.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">100</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/30
600/600 - 22s - loss: 0.7205 - accuracy: 0.7313 - val_loss: 0.5384 - val_accuracy: 0.7983 - 22s/epoch - 36ms/step
Epoch 2/30
600/600 - 20s - loss: 0.5059 - accuracy: 0.8041 - val_loss: 0.3950 - val_accuracy: 0.8497 - 20s/epoch - 33ms/step
Epoch 3/30
600/600 - 20s - loss: 0.4573 - accuracy: 0.8264 - val_loss: 0.3445 - val_accuracy: 0.8714 - 20s/epoch - 34ms/step
Epoch 4/30
600/600 - 22s - loss: 0.4143 - accuracy: 0.8426 - val_loss: 0.3686 - val_accuracy: 0.8589 - 22s/epoch - 37ms/step
Epoch 5/30
600/600 - 22s - loss: 0.3931 - accuracy: 0.8523 - val_loss: 0.3267 - val_accuracy: 0.8777 - 22s/epoch - 37ms/step
Epoch 6/30
600/600 - 20s - loss: 0.3743 - accuracy: 0.8583 - val_loss: 0.3313 - val_accuracy: 0.8770 - 20s/epoch - 34ms/step
Epoch 7/30
600/600 - 21s - loss: 0.3566 - accuracy: 0.8682 - val_loss: 0.3417 - val_accuracy: 0.8713 - 21s/epoch - 35ms/step
Epoch 8/30
600/600 - 20s - loss: 0.3489 - accuracy: 0.8695 - val_loss: 0.2893 - val_accuracy: 0.8906 - 20s/epoch - 34ms/step
Epoch 9/30
600/600 - 24s - loss: 0.3392 - accuracy: 0.8738 - val_loss: 0.3033 - val_accuracy: 0.8786 - 24s/epoch - 41ms/step
Epoch 10/30
600/600 - 21s - loss: 0.3287 - accuracy: 0.8775 - val_loss: 0.2523 - val_accuracy: 0.9053 - 21s/epoch - 35ms/step
Epoch 11/30
600/600 - 21s - loss: 0.3245 - accuracy: 0.8792 - val_loss: 0.2986 - val_accuracy: 0.8868 - 21s/epoch - 35ms/step
Epoch 12/30
600/600 - 20s - loss: 0.3175 - accuracy: 0.8813 - val_loss: 0.2618 - val_accuracy: 0.9012 - 20s/epoch - 34ms/step
Epoch 13/30
600/600 - 21s - loss: 0.3148 - accuracy: 0.8821 - val_loss: 0.2580 - val_accuracy: 0.9053 - 21s/epoch - 34ms/step
Epoch 14/30
600/600 - 20s - loss: 0.3087 - accuracy: 0.8848 - val_loss: 0.2545 - val_accuracy: 0.9045 - 20s/epoch - 34ms/step
Epoch 15/30
600/600 - 20s - loss: 0.3020 - accuracy: 0.8875 - val_loss: 0.2760 - val_accuracy: 0.8956 - 20s/epoch - 33ms/step
Epoch 16/30
600/600 - 20s - loss: 0.2981 - accuracy: 0.8891 - val_loss: 0.2282 - val_accuracy: 0.9165 - 20s/epoch - 33ms/step
Epoch 17/30
600/600 - 20s - loss: 0.2955 - accuracy: 0.8900 - val_loss: 0.2578 - val_accuracy: 0.9027 - 20s/epoch - 33ms/step
Epoch 18/30
600/600 - 20s - loss: 0.2942 - accuracy: 0.8907 - val_loss: 0.2385 - val_accuracy: 0.9121 - 20s/epoch - 34ms/step
Epoch 19/30
600/600 - 20s - loss: 0.2878 - accuracy: 0.8939 - val_loss: 0.2557 - val_accuracy: 0.9068 - 20s/epoch - 33ms/step
Epoch 20/30
600/600 - 21s - loss: 0.2839 - accuracy: 0.8929 - val_loss: 0.2379 - val_accuracy: 0.9119 - 21s/epoch - 36ms/step
Epoch 21/30
600/600 - 21s - loss: 0.2814 - accuracy: 0.8951 - val_loss: 0.2393 - val_accuracy: 0.9115 - 21s/epoch - 35ms/step
Epoch 22/30
600/600 - 20s - loss: 0.2817 - accuracy: 0.8954 - val_loss: 0.2348 - val_accuracy: 0.9107 - 20s/epoch - 34ms/step
Epoch 23/30
600/600 - 20s - loss: 0.2752 - accuracy: 0.8985 - val_loss: 0.2537 - val_accuracy: 0.9049 - 20s/epoch - 33ms/step
Epoch 24/30
600/600 - 20s - loss: 0.2733 - accuracy: 0.8989 - val_loss: 0.2543 - val_accuracy: 0.9049 - 20s/epoch - 33ms/step
Epoch 25/30
600/600 - 20s - loss: 0.2710 - accuracy: 0.8987 - val_loss: 0.2286 - val_accuracy: 0.9155 - 20s/epoch - 33ms/step
Epoch 26/30
600/600 - 20s - loss: 0.2694 - accuracy: 0.8999 - val_loss: 0.2304 - val_accuracy: 0.9144 - 20s/epoch - 33ms/step
Epoch 27/30
600/600 - 21s - loss: 0.2672 - accuracy: 0.9027 - val_loss: 0.2251 - val_accuracy: 0.9128 - 21s/epoch - 34ms/step
Epoch 28/30
600/600 - 20s - loss: 0.2675 - accuracy: 0.9003 - val_loss: 0.2216 - val_accuracy: 0.9181 - 20s/epoch - 34ms/step
Epoch 29/30
600/600 - 20s - loss: 0.2618 - accuracy: 0.9025 - val_loss: 0.2296 - val_accuracy: 0.9131 - 20s/epoch - 34ms/step
Epoch 30/30
600/600 - 20s - loss: 0.2595 - accuracy: 0.9050 - val_loss: 0.2177 - val_accuracy: 0.9192 - 20s/epoch - 34ms/step
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="SiBV8VEpDGIG" data-outputId="64256d26-e9a2-4e30-ba71-a6ff64b4f57f">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/381ca1624ae5aee43854667a097f57d47e4db87d.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="FJ4FG1m0DGMb" data-outputId="10fed59c-faba-4d05-b65c-6ef1fcbc2e3e">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model: 90.50333499908447
Train loss of the model:  0.259476900100708
Validation accuracy of the model:  0.9192000031471252
Validation loss of the model:  0.2177153378725052
Test Loss: 0.2177153378725052
Test Accuracy: 0.9192000031471252
</code></pre>
</div>
</div>
<div class="cell markdown" id="v0ZanFDyGZF5">
<p>The train and test accuracy for dropout + batch normalization is higher than the train and test accuracy for dropout + batch normalization + data augmentation. Hence, for the finalized model we will be using dropout + batch normalization</p>
</div>
<section id="final-model---increased-padding-and-filters--dropout--batch-normalization" class="cell markdown" id="GVYjVSrOErON">
<h1>Final Model - Increased Padding and filters + Dropout + Batch Normalization</h1>
</section>
<div class="cell markdown" id="&quot;89678745&quot;">
<p>Since it performs better with increasing epoch , we will fit the model with 40 epoch</p>
</div>
<div class="cell code" id="XDr5J2Om9e9K">
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">1</span>),padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>,padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">24</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>,padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>,padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>)))</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.3</span>))</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>], loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="6mllL_Oh4RUn" data-outputId="db26b951-a3ef-4d30-ad96-5b0b5c51c71e" data-scrolled="false">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span> <span class="dv">40</span>, batch_size<span class="op">=</span><span class="dv">100</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/40
600/600 [==============================] - 9s 14ms/step - loss: 0.6038 - accuracy: 0.7902 - val_loss: 0.4043 - val_accuracy: 0.8803
Epoch 2/40
600/600 [==============================] - 8s 14ms/step - loss: 0.3486 - accuracy: 0.8752 - val_loss: 0.2704 - val_accuracy: 0.9037
Epoch 3/40
600/600 [==============================] - 9s 14ms/step - loss: 0.3006 - accuracy: 0.8907 - val_loss: 0.2451 - val_accuracy: 0.9091
Epoch 4/40
600/600 [==============================] - 8s 14ms/step - loss: 0.2723 - accuracy: 0.9007 - val_loss: 0.2328 - val_accuracy: 0.9123
Epoch 5/40
600/600 [==============================] - 8s 14ms/step - loss: 0.2517 - accuracy: 0.9078 - val_loss: 0.2287 - val_accuracy: 0.9153
Epoch 6/40
600/600 [==============================] - 8s 14ms/step - loss: 0.2373 - accuracy: 0.9127 - val_loss: 0.2225 - val_accuracy: 0.9204
Epoch 7/40
600/600 [==============================] - 9s 14ms/step - loss: 0.2236 - accuracy: 0.9182 - val_loss: 0.2266 - val_accuracy: 0.9173
Epoch 8/40
600/600 [==============================] - 9s 14ms/step - loss: 0.2104 - accuracy: 0.9221 - val_loss: 0.2080 - val_accuracy: 0.9244
Epoch 9/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1990 - accuracy: 0.9254 - val_loss: 0.2140 - val_accuracy: 0.9229
Epoch 10/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1932 - accuracy: 0.9268 - val_loss: 0.2130 - val_accuracy: 0.9262
Epoch 11/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1862 - accuracy: 0.9301 - val_loss: 0.2051 - val_accuracy: 0.9307
Epoch 12/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1823 - accuracy: 0.9313 - val_loss: 0.2072 - val_accuracy: 0.9286
Epoch 13/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1718 - accuracy: 0.9329 - val_loss: 0.2221 - val_accuracy: 0.9273
Epoch 14/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1671 - accuracy: 0.9371 - val_loss: 0.2110 - val_accuracy: 0.9281
Epoch 15/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1624 - accuracy: 0.9385 - val_loss: 0.2172 - val_accuracy: 0.9266
Epoch 16/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1592 - accuracy: 0.9392 - val_loss: 0.2363 - val_accuracy: 0.9270
Epoch 17/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1561 - accuracy: 0.9406 - val_loss: 0.2225 - val_accuracy: 0.9251
Epoch 18/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1520 - accuracy: 0.9420 - val_loss: 0.2163 - val_accuracy: 0.9290
Epoch 19/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1477 - accuracy: 0.9441 - val_loss: 0.2129 - val_accuracy: 0.9319
Epoch 20/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1443 - accuracy: 0.9452 - val_loss: 0.2181 - val_accuracy: 0.9254
Epoch 21/40
600/600 [==============================] - 9s 15ms/step - loss: 0.1400 - accuracy: 0.9472 - val_loss: 0.2164 - val_accuracy: 0.9264
Epoch 22/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1398 - accuracy: 0.9456 - val_loss: 0.2209 - val_accuracy: 0.9303
Epoch 23/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1390 - accuracy: 0.9474 - val_loss: 0.2180 - val_accuracy: 0.9315
Epoch 24/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1331 - accuracy: 0.9486 - val_loss: 0.2225 - val_accuracy: 0.9287
Epoch 25/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1276 - accuracy: 0.9506 - val_loss: 0.2187 - val_accuracy: 0.9318
Epoch 26/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1271 - accuracy: 0.9511 - val_loss: 0.2295 - val_accuracy: 0.9298
Epoch 27/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1228 - accuracy: 0.9517 - val_loss: 0.2131 - val_accuracy: 0.9311
Epoch 28/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1214 - accuracy: 0.9536 - val_loss: 0.2197 - val_accuracy: 0.9321
Epoch 29/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1196 - accuracy: 0.9542 - val_loss: 0.2255 - val_accuracy: 0.9308
Epoch 30/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1195 - accuracy: 0.9542 - val_loss: 0.2361 - val_accuracy: 0.9297
Epoch 31/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1179 - accuracy: 0.9548 - val_loss: 0.2393 - val_accuracy: 0.9295
Epoch 32/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.2192 - val_accuracy: 0.9300
Epoch 33/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1159 - accuracy: 0.9551 - val_loss: 0.2295 - val_accuracy: 0.9306
Epoch 34/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1136 - accuracy: 0.9572 - val_loss: 0.2325 - val_accuracy: 0.9295
Epoch 35/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1098 - accuracy: 0.9579 - val_loss: 0.2427 - val_accuracy: 0.9321
Epoch 36/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1078 - accuracy: 0.9581 - val_loss: 0.2671 - val_accuracy: 0.9298
Epoch 37/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1084 - accuracy: 0.9580 - val_loss: 0.2585 - val_accuracy: 0.9288
Epoch 38/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1044 - accuracy: 0.9601 - val_loss: 0.2550 - val_accuracy: 0.9358
Epoch 39/40
600/600 [==============================] - 9s 14ms/step - loss: 0.1032 - accuracy: 0.9601 - val_loss: 0.2572 - val_accuracy: 0.9334
Epoch 40/40
600/600 [==============================] - 8s 14ms/step - loss: 0.1023 - accuracy: 0.9604 - val_loss: 0.2558 - val_accuracy: 0.9322
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="MgpHFBF63_BQ" data-outputId="8043320d-81f3-46f1-c709-c93f7fa1679e">
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/14ea7ca7a9e49582fe2b9c5f2fb8aa880fb1930e.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="DfCRzCiz3_TY" data-outputId="8fa162a7-0726-4282-8ad6-5706a54db3b9">
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train accuracy of the model:  0.9604166746139526
Train loss of the model:  0.10234038531780243
Validation accuracy of the model:  0.932200014591217
Validation loss of the model:  0.2558209002017975
Test Loss: 0.2558209002017975
Test Accuracy: 0.932200014591217
</code></pre>
</div>
</div>
<div class="cell markdown" id="4f46dddc">
<p>The train accuracy is amazing at 96% and the validation accuracy is also very high at 93%</p>
</div>
<section id="results" class="cell markdown" id="EoY13b5JIFus">
<h1>Results</h1>
</section>
<div class="cell code" id="sXdLBWhV8a7O">
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># confusion matrix</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:910,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="IW3oMgkw8ZwD" data-outputId="ae1462ff-b0a6-471b-e1cc-be5727b9b1cf">
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>y_pred_classes <span class="op">=</span> np.argmax(y_pred, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.argmax(y_test, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>confusion_mtx <span class="op">=</span> confusion_matrix(y_true, y_pred_classes) </span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>f,ax <span class="op">=</span> plt.subplots(figsize <span class="op">=</span> (<span class="dv">15</span>,<span class="dv">15</span>))</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_mtx, annot<span class="op">=</span><span class="va">True</span>, linewidths<span class="op">=</span><span class="fl">0.1</span>, cmap <span class="op">=</span> <span class="st">&quot;gist_yarg_r&quot;</span>, linecolor<span class="op">=</span><span class="st">&quot;black&quot;</span>, fmt<span class="op">=</span><span class="st">&#39;.0f&#39;</span>, ax<span class="op">=</span>ax)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Predicted Label&quot;</span>)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;True Label&quot;</span>)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion Matrix&quot;</span>)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>313/313 [==============================] - 1s 2ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_2dccf20de1f34058aaa722d6dbb2ab61/49ac0a1b7c05b0c86cd7a9755d62bc892749ee96.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="d6YBuM2-80ZI" data-outputId="8050988a-ad22-4b39-c43b-69a25ac5c385">
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(confusion_mtx)):</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Class:&quot;</span>,<span class="bu">str</span>(i))</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Number of Wrong Prediction:&quot;</span>, <span class="bu">str</span>(<span class="bu">sum</span>(confusion_mtx[i])<span class="op">-</span>confusion_mtx[i][i]), <span class="st">&quot;out of 1000&quot;</span>)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Percentage of True Prediction: </span><span class="sc">{:.2f}</span><span class="st">%&quot;</span>.<span class="bu">format</span>(confusion_mtx[i][i] <span class="op">/</span> <span class="dv">10</span>))</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;***********************************************************&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Class: 0
Number of Wrong Prediction: 88 out of 1000
Percentage of True Prediction: 91.20%
***********************************************************
Class: 1
Number of Wrong Prediction: 14 out of 1000
Percentage of True Prediction: 98.60%
***********************************************************
Class: 2
Number of Wrong Prediction: 95 out of 1000
Percentage of True Prediction: 90.50%
***********************************************************
Class: 3
Number of Wrong Prediction: 69 out of 1000
Percentage of True Prediction: 93.10%
***********************************************************
Class: 4
Number of Wrong Prediction: 84 out of 1000
Percentage of True Prediction: 91.60%
***********************************************************
Class: 5
Number of Wrong Prediction: 14 out of 1000
Percentage of True Prediction: 98.60%
***********************************************************
Class: 6
Number of Wrong Prediction: 256 out of 1000
Percentage of True Prediction: 74.40%
***********************************************************
Class: 7
Number of Wrong Prediction: 23 out of 1000
Percentage of True Prediction: 97.70%
***********************************************************
Class: 8
Number of Wrong Prediction: 10 out of 1000
Percentage of True Prediction: 99.00%
***********************************************************
Class: 9
Number of Wrong Prediction: 25 out of 1000
Percentage of True Prediction: 97.50%
***********************************************************
</code></pre>
</div>
</div>
<div class="cell markdown" id="03d73495">
<p>Our model is really good as the percentage of true predictions is really high with the highest being 99%</p>
</div>
<div class="cell code">
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>jupyter nbconvert <span class="op">--</span>to html my<span class="op">-</span>notebook.ipynb</span></code></pre></div>
</div>
</body>
</html>
